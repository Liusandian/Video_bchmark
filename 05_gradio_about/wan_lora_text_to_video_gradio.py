import torch.multiprocessing as mp
import gradio as gr
import tempfile
import os
from typing import Optional
import torch

from diffsynth_engine.pipelines import WanVideoPipeline, WanModelConfig
from diffsynth_engine.utils.download import fetch_model
from diffsynth_engine.utils.video import save_video


# å…¨å±€å˜é‡
pipe = None
current_lora_path = None
current_lora_scale = None

# é¢„å®šä¹‰çš„ LoRA æ¨¡å‹é€‰é¡¹
LORA_OPTIONS = {
    "æ—  LoRA": None,
    "WAN Silver Style": "VoidOc/wan_silver",
    # å¯ä»¥æ·»åŠ æ›´å¤š LoRA æ¨¡å‹é€‰é¡¹
}

# é¢„å®šä¹‰çš„æç¤ºè¯æ¨¡æ¿
PROMPT_TEMPLATES = {
    "æ¨±èŠ±å¥³æ€§": "ä¸€å¼ äºšæ´²å¥³æ€§åœ¨æ°´ä¸­è¢«æ¨±èŠ±ç¯ç»•çš„ç…§ç‰‡ã€‚å¥¹æ‹¥æœ‰ç™½çš™çš„è‚Œè‚¤å’Œç²¾è‡´çš„é¢å®¹ï¼Œæ¨±èŠ±æ•£è½åœ¨å¥¹çš„è„¸é¢Šï¼Œå¥¹è½»ç›ˆåœ°æ¼‚æµ®åœ¨æ°´ä¸­ã€‚é˜³å…‰é€è¿‡æ°´é¢æ´’ä¸‹ï¼Œå½¢æˆæ–‘é©³çš„å…‰å½±ï¼Œè¥é€ å‡ºä¸€ç§å®é™è€Œè¶…å‡¡è„±ä¿—çš„æ°›å›´ã€‚å¥¹çš„é•¿å‘åœ¨æ°´ä¸­è½»è½»é£˜åŠ¨ï¼Œçœ¼ç¥æ¸©æŸ”è€Œå®é™ï¼Œä»¿ä½›ä¸å‘¨å›´çš„è‡ªç„¶ç¯å¢ƒèä¸ºä¸€ä½“ã€‚èƒŒæ™¯æ˜¯æ·¡ç²‰è‰²çš„æ¨±èŠ±èŠ±ç“£ç¼“ç¼“éšç€æ°´æ³¢ä¸Šæ¼‚æµ®ï¼Œå¢æ·»äº†ä¸€æŠ¹æ¢¦å¹»è‰²å½©ã€‚ç”»é¢æ•´ä½“å‘ˆç°å‡ºæŸ”å’Œçš„è‰²è°ƒï¼Œå¸¦æœ‰ç»†è…»çš„å…‰å½±æ•ˆæœã€‚ä¸­æ™¯è„¸éƒ¨äººåƒç‰¹å†™ï¼Œä¿¯è§†è§†è§’ã€‚,wan_silver,wan_silver",
    "åŸå¸‚å¤œæ™¯": "ç¹åéƒ½å¸‚çš„å¤œæ™¯ï¼Œéœ“è™¹ç¯é—ªçƒï¼Œè½¦æµå¦‚ç»‡ï¼Œé«˜æ¥¼å¤§å¦ç¯ç«é€šæ˜ï¼Œè¥é€ å‡ºç°ä»£éƒ½å¸‚çš„ç¹åæ™¯è±¡",
    "è‡ªç„¶é£å…‰": "å±±æ°´é£å…‰ï¼Œé’å±±ç»¿æ°´ï¼Œäº‘é›¾ç¼­ç»•ï¼Œç€‘å¸ƒé£æµç›´ä¸‹ï¼Œé¸Ÿè¯­èŠ±é¦™ï¼Œå±•ç°å¤§è‡ªç„¶çš„å£®ç¾æ™¯è‰²",
    "äººç‰©ç‰¹å†™": "å¹´è½»å¥³æ€§è‚–åƒï¼Œæ¸©æŸ”çš„çœ¼ç¥ï¼ŒæŸ”å’Œçš„å…‰çº¿ï¼Œç»†è…»çš„çš®è‚¤è´¨æ„Ÿï¼Œä¸“ä¸šæ‘„å½±é£æ ¼",
    "ç§‘å¹»åœºæ™¯": "æœªæ¥ç§‘æŠ€åŸå¸‚ï¼Œé£è¡Œæ±½è½¦ç©¿æ¢­ï¼Œå…¨æ¯æŠ•å½±å¹¿å‘Šï¼Œæœºå™¨äººè¡Œèµ°åœ¨è¡—é“ä¸Šï¼Œå……æ»¡ç§‘æŠ€æ„Ÿçš„æœªæ¥ä¸–ç•Œ",
}


def initialize_pipeline():
    """åˆå§‹åŒ–è§†é¢‘ç”Ÿæˆç®¡é“"""
    global pipe
    if pipe is None:
        print("æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹ï¼Œè¯·ç¨å€™...")
        mp.set_start_method("spawn", force=True)
        config = WanModelConfig(
            model_path=fetch_model("MusePublic/wan2.1-1.3b", path="dit.safetensors"),
            t5_path=fetch_model("muse/wan2.1-umt5", path="umt5.safetensors"),
            vae_path=fetch_model("muse/wan2.1-vae", path="vae.safetensors"),
            dit_fsdp=True,
        )
        pipe = WanVideoPipeline.from_pretrained(
            config, 
            parallelism=4, 
            use_cfg_parallel=True, 
            offload_mode="cpu_offload"
        )
        print("æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼")


def load_lora_model(lora_model_name: str, lora_scale: float, progress=gr.Progress()):
    """åŠ è½½ LoRA æ¨¡å‹"""
    global pipe, current_lora_path, current_lora_scale
    
    try:
        initialize_pipeline()
        
        if lora_model_name == "æ—  LoRA" or lora_model_name not in LORA_OPTIONS:
            current_lora_path = None
            current_lora_scale = None
            return "âœ… å·²ç§»é™¤ LoRA æ¨¡å‹"
        
        lora_path = LORA_OPTIONS[lora_model_name]
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°åŠ è½½ LoRA
        if current_lora_path != lora_path or current_lora_scale != lora_scale:
            progress(0.5, desc="åŠ è½½ LoRA æ¨¡å‹...")
            
            if lora_model_name == "WAN Silver Style":
                pipe.load_lora(
                    path=fetch_model("VoidOc/wan_silver", revision="ckpt-15", path="15.safetensors"),
                    scale=lora_scale,
                    fused=False,
                )
            
            current_lora_path = lora_path
            current_lora_scale = lora_scale
            progress(1.0, desc="LoRA åŠ è½½å®Œæˆ")
            return f"âœ… å·²åŠ è½½ LoRA: {lora_model_name} (æƒé‡: {lora_scale})"
        else:
            return f"âœ… LoRA å·²åŠ è½½: {lora_model_name} (æƒé‡: {lora_scale})"
            
    except Exception as e:
        return f"âŒ åŠ è½½ LoRA å¤±è´¥: {str(e)}"


def generate_video(
    prompt: str,
    negative_prompt: str,
    lora_model: str,
    lora_scale: float,
    num_frames: int,
    width: int,
    height: int,
    seed: int,
    progress=gr.Progress()
):
    """ç”Ÿæˆè§†é¢‘çš„ä¸»è¦å‡½æ•°"""
    try:
        # æ£€æŸ¥æç¤ºè¯
        if not prompt.strip():
            return None, "è¯·è¾“å…¥æç¤ºè¯ï¼"
        
        # åˆå§‹åŒ–ç®¡é“
        progress(0.1, desc="åˆå§‹åŒ–æ¨¡å‹...")
        initialize_pipeline()
        
        # åŠ è½½ LoRA æ¨¡å‹
        progress(0.2, desc="åŠ è½½ LoRA æ¨¡å‹...")
        lora_status = load_lora_model(lora_model, lora_scale, progress)
        print(lora_status)
        
        # ç”Ÿæˆè§†é¢‘
        progress(0.3, desc="å¼€å§‹ç”Ÿæˆè§†é¢‘...")
        video = pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            num_frames=num_frames,
            width=width,
            height=height,
            seed=seed,
        )
        
        # ä¿å­˜è§†é¢‘
        progress(0.9, desc="ä¿å­˜è§†é¢‘æ–‡ä»¶...")
        with tempfile.NamedTemporaryFile(suffix=".mp4", delete=False) as tmp_file:
            output_path = tmp_file.name
        
        save_video(video, output_path, fps=15)
        progress(1.0, desc="å®Œæˆï¼")
        
        return output_path, f"è§†é¢‘ç”ŸæˆæˆåŠŸï¼\n{lora_status}"
        
    except Exception as e:
        error_msg = f"ç”Ÿæˆè§†é¢‘æ—¶å‡ºé”™: {str(e)}"
        print(error_msg)
        return None, error_msg


def update_prompt_from_template(template_name: str):
    """æ ¹æ®æ¨¡æ¿æ›´æ–°æç¤ºè¯"""
    if template_name in PROMPT_TEMPLATES:
        return PROMPT_TEMPLATES[template_name]
    return ""


def create_interface():
    """åˆ›å»º Gradio ç•Œé¢"""
    
    with gr.Blocks(title="WAN LoRA æ–‡ç”Ÿè§†é¢‘ç”Ÿæˆå™¨", theme=gr.themes.Soft()) as interface:
        gr.Markdown("# ğŸ¬ WAN LoRA æ–‡ç”Ÿè§†é¢‘ç”Ÿæˆå™¨")
        gr.Markdown("ä½¿ç”¨ LoRA æ¨¡å‹å¢å¼ºçš„æ–‡æœ¬åˆ°è§†é¢‘ç”Ÿæˆï¼Œæ”¯æŒå¤šç§è‰ºæœ¯é£æ ¼ï¼")
        
        with gr.Row():
            with gr.Column(scale=1):
                # æç¤ºè¯è®¾ç½®
                gr.Markdown("### ğŸ“ æç¤ºè¯è®¾ç½®")
                
                with gr.Row():
                    prompt_template = gr.Dropdown(
                        label="æç¤ºè¯æ¨¡æ¿",
                        choices=list(PROMPT_TEMPLATES.keys()),
                        value="æ¨±èŠ±å¥³æ€§",
                        info="é€‰æ‹©é¢„è®¾æ¨¡æ¿å¿«é€Ÿå¼€å§‹"
                    )
                    
                prompt = gr.Textbox(
                    label="æç¤ºè¯ (æè¿°ä½ æƒ³è¦çš„è§†é¢‘å†…å®¹)",
                    placeholder="è¯¦ç»†æè¿°ä½ æƒ³è¦ç”Ÿæˆçš„è§†é¢‘åœºæ™¯ã€äººç‰©ã€åŠ¨ä½œã€é£æ ¼ç­‰...",
                    lines=4,
                    value=PROMPT_TEMPLATES["æ¨±èŠ±å¥³æ€§"],
                    info="æ”¯æŒä¸­è‹±æ–‡ï¼Œå»ºè®®è¯¦ç»†æè¿°"
                )
                
                negative_prompt = gr.Textbox(
                    label="è´Ÿé¢æç¤ºè¯",
                    placeholder="æè¿°ä¸æƒ³è¦çš„å†…å®¹...",
                    lines=2,
                    value="è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°",
                    info="å¸®åŠ©æ’é™¤ä¸æƒ³è¦çš„å…ƒç´ "
                )
                
                # LoRA è®¾ç½®
                gr.Markdown("### ğŸ¨ LoRA æ¨¡å‹è®¾ç½®")
                
                with gr.Row():
                    lora_model = gr.Dropdown(
                        label="LoRA æ¨¡å‹",
                        choices=list(LORA_OPTIONS.keys()),
                        value="WAN Silver Style",
                        info="é€‰æ‹©è‰ºæœ¯é£æ ¼æ¨¡å‹"
                    )
                    
                    lora_scale = gr.Slider(
                        label="LoRA æƒé‡",
                        minimum=0.0,
                        maximum=2.0,
                        value=1.0,
                        step=0.1,
                        info="æ§åˆ¶é£æ ¼å¼ºåº¦"
                    )
                
                # è§†é¢‘å‚æ•°
                gr.Markdown("### âš™ï¸ è§†é¢‘å‚æ•°")
                
                with gr.Row():
                    num_frames = gr.Slider(
                        label="è§†é¢‘å¸§æ•°",
                        minimum=25,
                        maximum=121,
                        value=81,
                        step=8,
                        info="æ›´å¤šå¸§æ•° = æ›´é•¿è§†é¢‘"
                    )
                    
                    seed = gr.Number(
                        label="éšæœºç§å­",
                        value=42,
                        precision=0,
                        info="å›ºå®šç§å­è·å¾—ä¸€è‡´ç»“æœ"
                    )
                
                with gr.Row():
                    width = gr.Slider(
                        label="è§†é¢‘å®½åº¦",
                        minimum=256,
                        maximum=768,
                        value=480,
                        step=64
                    )
                    
                    height = gr.Slider(
                        label="è§†é¢‘é«˜åº¦",
                        minimum=256,
                        maximum=832,
                        value=832,
                        step=64,
                        info="æ¨èç«–å±æ¯”ä¾‹"
                    )
                
                generate_btn = gr.Button("ğŸ¬ ç”Ÿæˆè§†é¢‘", variant="primary", size="lg")
                
            with gr.Column(scale=1):
                # è¾“å‡ºåŒºåŸŸ
                output_video = gr.Video(
                    label="ç”Ÿæˆçš„è§†é¢‘",
                    height=450
                )
                
                status_text = gr.Textbox(
                    label="çŠ¶æ€ä¿¡æ¯",
                    interactive=False,
                    lines=3,
                    value="ç­‰å¾…å¼€å§‹ç”Ÿæˆ..."
                )
        
        # ä½¿ç”¨ç¤ºä¾‹å’Œæç¤º
        gr.Markdown("## ğŸ’¡ ä½¿ç”¨æŒ‡å—")
        
        with gr.Accordion("ğŸ“‹ è¯¦ç»†è¯´æ˜", open=False):
            gr.Markdown("""
            ### LoRA æ¨¡å‹è¯´æ˜
            - **WAN Silver Style**: é“¶è‰²è‰ºæœ¯é£æ ¼ï¼Œé€‚åˆäººåƒå’Œå”¯ç¾åœºæ™¯
            - **LoRA æƒé‡**: 0.0-2.0ï¼Œå»ºè®®ä»1.0å¼€å§‹è°ƒè¯•
            
            ### æç¤ºè¯æŠ€å·§
            - æ”¯æŒä¸­è‹±æ–‡æ··åˆè¾“å…¥
            - å¯ä»¥åœ¨æç¤ºè¯ä¸­åŠ å…¥ LoRA è§¦å‘è¯ï¼ˆå¦‚ "wan_silver"ï¼‰
            - è¯¦ç»†æè¿°åœºæ™¯ã€äººç‰©ã€åŠ¨ä½œã€å…‰å½±æ•ˆæœ
            - æŒ‡å®šè§†è§’å’Œæ„å›¾ï¼ˆå¦‚"ä¸­æ™¯è„¸éƒ¨äººåƒç‰¹å†™ï¼Œä¿¯è§†è§†è§’"ï¼‰
            
            ### å‚æ•°å»ºè®®
            - **å¸§æ•°**: 81å¸§çº¦5ç§’è§†é¢‘ï¼ˆ15fpsï¼‰
            - **åˆ†è¾¨ç‡**: 480x832é€‚åˆç«–å±è§‚çœ‹
            - **ç§å­**: ç›¸åŒè®¾ç½®ä¸‹å›ºå®šç§å­äº§ç”Ÿä¸€è‡´ç»“æœ
            
            ### æ€§èƒ½ä¼˜åŒ–
            - é¦–æ¬¡ä½¿ç”¨éœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶
            - æ¨èä½¿ç”¨ GPU åŠ é€Ÿ
            - ç”Ÿæˆæ—¶é—´çº¦ 3-10 åˆ†é’Ÿï¼ˆå–å†³äºç¡¬ä»¶ï¼‰
            """)
        
        with gr.Accordion("ğŸ¯ æç¤ºè¯ç¤ºä¾‹", open=False):
            gr.Markdown("""
            **äººç‰©åœºæ™¯**:
            - "ä¸€ä½ä¼˜é›…çš„å¥³æ€§åœ¨å¤å…¸èŠ±å›­ä¸­æ¼«æ­¥ï¼Œç©¿ç€é£˜é€¸çš„ç™½è‰²é•¿è£™ï¼Œé˜³å…‰é€è¿‡æ ‘å¶æ´’åœ¨å¥¹èº«ä¸Šï¼Œè¥é€ å‡ºæ¢¦å¹»èˆ¬çš„å…‰å½±æ•ˆæœ"
            
            **è‡ªç„¶é£å…‰**:
            - "å£®è§‚çš„ç€‘å¸ƒä»é«˜å±±ä¸Šå€¾æ³»è€Œä¸‹ï¼Œæ°´é›¾å¼¥æ¼«ï¼Œå½©è™¹æ¨ªè·¨å…¶ä¸­ï¼Œå‘¨å›´ç»¿æ ‘ç¯ç»•ï¼Œé¸Ÿå„¿åœ¨ç©ºä¸­é£ç¿”"
            
            **åŸå¸‚å¤œæ™¯**:
            - "ç°ä»£éƒ½å¸‚çš„å¤œæ™šï¼Œéœ“è™¹ç¯ç’€ç’¨å¤ºç›®ï¼Œè½¦æµç©¿æ¢­åœ¨è¡—é“ä¸Šï¼Œæ‘©å¤©å¤§æ¥¼ç¯ç«é€šæ˜ï¼Œå±•ç°éƒ½å¸‚çš„ç¹åä¸æ´»åŠ›"
            
            **è‰ºæœ¯é£æ ¼**:
            - "æ°´å½©ç”»é£æ ¼çš„æ˜¥æ—¥æ¨±èŠ±é£èˆåœºæ™¯ï¼Œç²‰è‰²èŠ±ç“£åœ¨å¾®é£ä¸­ç¿©ç¿©èµ·èˆï¼ŒèƒŒæ™¯æ˜¯æœ¦èƒ§çš„å±±å³¦ï¼Œæ•´ä½“è‰²è°ƒæ¸©æŸ”æ¢¦å¹»"
            """)
        
        # äº‹ä»¶ç»‘å®š
        prompt_template.change(
            fn=update_prompt_from_template,
            inputs=[prompt_template],
            outputs=[prompt]
        )
        
        generate_btn.click(
            fn=generate_video,
            inputs=[
                prompt,
                negative_prompt,
                lora_model,
                lora_scale,
                num_frames,
                width,
                height,
                seed
            ],
            outputs=[output_video, status_text],
            show_progress=True
        )
    
    return interface


if __name__ == "__main__":
    # æ£€æŸ¥ç¯å¢ƒ
    if torch.cuda.is_available():
        print(f"ğŸ® æ£€æµ‹åˆ°GPU: {torch.cuda.get_device_name()}")
    else:
        print("âš ï¸  æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè¿è¡Œï¼ˆé€Ÿåº¦å¾ˆæ…¢ï¼‰")
    
    # åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢
    interface = create_interface()
    interface.launch(
        server_name="0.0.0.0",
        server_port=7861,  # ä½¿ç”¨ä¸åŒç«¯å£é¿å…å†²çª
        share=False,
        debug=True,
        show_error=True
    ) 