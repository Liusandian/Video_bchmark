import torch.multiprocessing as mp
import gradio as gr
import tempfile
import os
from PIL import Image
import torch

from diffsynth_engine.pipelines import WanVideoPipeline, WanModelConfig
from diffsynth_engine.utils.download import fetch_model
from diffsynth_engine.utils.video import save_video


# å…¨å±€å˜é‡å­˜å‚¨ç®¡é“
pipe = None


def initialize_pipeline():
    """åˆå§‹åŒ–è§†é¢‘ç”Ÿæˆç®¡é“"""
    global pipe
    if pipe is None:
        print("æ­£åœ¨åˆå§‹åŒ–æ¨¡å‹ï¼Œè¯·ç¨å€™...")
        mp.set_start_method("spawn", force=True)
        config = WanModelConfig(
            model_path=fetch_model("muse/wan2.1-i2v-14b-480p-bf16", path="dit.safetensors"),
            t5_path=fetch_model("muse/wan2.1-umt5", path="umt5.safetensors"),
            vae_path=fetch_model("muse/wan2.1-vae", path="vae.safetensors"),
            image_encoder_path=fetch_model(
                "muse/open-clip-xlm-roberta-large-vit-huge-14",
                path="open-clip-xlm-roberta-large-vit-huge-14.safetensors",
            ),
            dit_fsdp=True,
        )
        pipe = WanVideoPipeline.from_pretrained(
            config, 
            parallelism=4, 
            use_cfg_parallel=True, 
            offload_mode="cpu_offload"
        )
        print("æ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼")


def generate_video(
    input_image,
    prompt,
    negative_prompt,
    num_frames,
    width,
    height,
    seed,
    progress=gr.Progress()
):
    """ç”Ÿæˆè§†é¢‘çš„ä¸»è¦å‡½æ•°"""
    try:
        # æ£€æŸ¥è¾“å…¥å›¾åƒ
        if input_image is None:
            return None, "è¯·å…ˆä¸Šä¼ ä¸€å¼ å›¾åƒï¼"
        
        # åˆå§‹åŒ–ç®¡é“
        progress(0.1, desc="åˆå§‹åŒ–æ¨¡å‹...")
        initialize_pipeline()
        
        # é¢„å¤„ç†å›¾åƒ
        progress(0.2, desc="å¤„ç†è¾“å…¥å›¾åƒ...")
        if isinstance(input_image, str):
            image = Image.open(input_image).convert("RGB")
        else:
            image = input_image.convert("RGB")
        
        # ç”Ÿæˆè§†é¢‘
        progress(0.3, desc="å¼€å§‹ç”Ÿæˆè§†é¢‘...")
        video = pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            input_image=image,
            num_frames=num_frames,
            width=width,
            height=height,
            seed=seed,
        )
        
        # ä¿å­˜è§†é¢‘
        progress(0.9, desc="ä¿å­˜è§†é¢‘æ–‡ä»¶...")
        with tempfile.NamedTemporaryFile(suffix=".mp4", delete=False) as tmp_file:
            output_path = tmp_file.name
        
        save_video(video, output_path, fps=15)
        progress(1.0, desc="å®Œæˆï¼")
        
        return output_path, "è§†é¢‘ç”ŸæˆæˆåŠŸï¼"
        
    except Exception as e:
        error_msg = f"ç”Ÿæˆè§†é¢‘æ—¶å‡ºé”™: {str(e)}"
        print(error_msg)
        return None, error_msg


def create_interface():
    """åˆ›å»º Gradio ç•Œé¢"""
    
    with gr.Blocks(title="WAN å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆå™¨", theme=gr.themes.Soft()) as interface:
        gr.Markdown("# ğŸ¬ WAN å›¾åƒåˆ°è§†é¢‘ç”Ÿæˆå™¨")
        gr.Markdown("ä¸Šä¼ ä¸€å¼ å›¾åƒï¼Œè¾“å…¥æè¿°æ–‡å­—ï¼Œç”Ÿæˆç²¾å½©çš„è§†é¢‘ï¼")
        
        with gr.Row():
            with gr.Column(scale=1):
                # è¾“å…¥æ§ä»¶
                input_image = gr.Image(
                    label="ä¸Šä¼ å›¾åƒ",
                    type="pil",
                    height=300
                )
                
                prompt = gr.Textbox(
                    label="æç¤ºè¯ (æè¿°ä½ æƒ³è¦çš„è§†é¢‘å†…å®¹)",
                    placeholder="ä¾‹å¦‚ï¼šSummer beach vacation style, a white cat wearing sunglasses sits on a surfboard...",
                    lines=4,
                    value="Summer beach vacation style, a white cat wearing sunglasses sits on a surfboard. The fluffy-furred feline gazes directly at the camera with a relaxed expression."
                )
                
                negative_prompt = gr.Textbox(
                    label="è´Ÿé¢æç¤ºè¯ (æè¿°ä¸æƒ³è¦çš„å†…å®¹)",
                    placeholder="ä¾‹å¦‚ï¼šblurry, low quality, distorted...",
                    lines=2,
                    value="blurry, low quality, distorted, ugly, deformed"
                )
                
                with gr.Row():
                    num_frames = gr.Slider(
                        label="è§†é¢‘å¸§æ•°",
                        minimum=25,
                        maximum=121,
                        value=81,
                        step=8,
                        info="æ›´å¤šå¸§æ•° = æ›´é•¿è§†é¢‘ï¼Œä½†ç”Ÿæˆæ—¶é—´æ›´ä¹…"
                    )
                    
                    seed = gr.Number(
                        label="éšæœºç§å­",
                        value=42,
                        precision=0,
                        info="ç›¸åŒç§å­ä¼šäº§ç”Ÿç›¸ä¼¼ç»“æœ"
                    )
                
                with gr.Row():
                    width = gr.Slider(
                        label="è§†é¢‘å®½åº¦",
                        minimum=256,
                        maximum=768,
                        value=480,
                        step=64
                    )
                    
                    height = gr.Slider(
                        label="è§†é¢‘é«˜åº¦", 
                        minimum=256,
                        maximum=768,
                        value=480,
                        step=64
                    )
                
                generate_btn = gr.Button("ğŸ¬ ç”Ÿæˆè§†é¢‘", variant="primary", size="lg")
                
            with gr.Column(scale=1):
                # è¾“å‡ºæ§ä»¶
                output_video = gr.Video(
                    label="ç”Ÿæˆçš„è§†é¢‘",
                    height=400
                )
                
                status_text = gr.Textbox(
                    label="çŠ¶æ€",
                    interactive=False,
                    value="ç­‰å¾…å¼€å§‹..."
                )
        
        # ç¤ºä¾‹
        gr.Markdown("## ğŸ’¡ ä½¿ç”¨æç¤º")
        gr.Markdown("""
        - **ä¸Šä¼ å›¾åƒ**: æ”¯æŒ JPGã€PNG ç­‰å¸¸è§æ ¼å¼
        - **æç¤ºè¯**: è¯¦ç»†æè¿°ä½ å¸Œæœ›è§†é¢‘ä¸­å‘ç”Ÿçš„åŠ¨ä½œå’Œåœºæ™¯
        - **å¸§æ•°**: 25-121å¸§ï¼Œå»ºè®®81å¸§ä»¥è·å¾—è¾ƒå¥½çš„æ•ˆæœ
        - **å°ºå¯¸**: å»ºè®®ä½¿ç”¨480x480æˆ–ç±»ä¼¼æ¯”ä¾‹ï¼Œè¿‡å¤§ä¼šå½±å“ç”Ÿæˆé€Ÿåº¦
        - **ç§å­**: å›ºå®šç§å­å¯ä»¥è·å¾—å¯é‡å¤çš„ç»“æœ
        """)
        
        # ç»‘å®šäº‹ä»¶
        generate_btn.click(
            fn=generate_video,
            inputs=[
                input_image,
                prompt, 
                negative_prompt,
                num_frames,
                width,
                height,
                seed
            ],
            outputs=[output_video, status_text],
            show_progress=True
        )
    
    return interface


if __name__ == "__main__":
    # æ£€æŸ¥ CUDA å¯ç”¨æ€§
    if torch.cuda.is_available():
        print(f"CUDA å¯ç”¨ï¼ŒGPU: {torch.cuda.get_device_name()}")
    else:
        print("CUDA ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPUï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
    
    # åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢
    interface = create_interface()
    interface.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,  # è®¾ç½®ä¸º True å¯ä»¥è·å¾—å…¬å…±é“¾æ¥
        debug=True
    ) 